### Additional Requirements

- FFmpeg: Required for audio playback
  - On macOS: `brew install ffmpeg`
  - On Ubuntu/Debian: `sudo apt-get install ffmpeg`
  - On Windows: Download from [ffmpeg.org](https://ffmpeg.org/download.html) and add to PATH# Facial Action Unit Analysis Tool

This application helps analyze facial action unit values generated by OpenFace. It allows you to annotate facial actions in videos and generate both a modified CSV file and an annotated video.

## Features

- Video playback with audio synchronized with action unit data
- Support for two CSV input files with identical action annotations
- Button interface to mark frames with specific facial actions (press and hold while action is occurring)
- Keyboard shortcuts (number keys 1-9) for activating action buttons with visual feedback
- Real-time action code text overlay on video during annotation
- Export annotated CSV files with action codes for each frame
- Generate output video with on-screen action labels
- Space-efficient UI layout optimized for 1280x720 videos

## Action Codes

The following action codes are supported:

- **RE**: Raise Eyebrows
- **SS**: Soft Smile
- **BS**: Big Smile
- **BL**: Blink
- **ES**: Close Eyes Softly
- **ET**: Close Eyes Tightly
- **WN**: Wrinkle Nose
- **PL**: Pucker Lips
- **SO**: Say "O"
- **SE**: Say "E"

## Installation

1. Clone this repository
2. Install the required dependencies:

```bash
pip install -r requirements.txt
```

## Usage

1. Run the application:

```bash
python main.py
```

1. Select the input video file and one or two CSV files containing OpenFace action unit data
2. Play the video and press/hold the action buttons when the corresponding actions are being performed
3. Release the buttons when the action stops
4. Click "Generate Output Files" to process and save the results in the "output" folder

## Project Structure

- `main.py`: Main entry point and application controller
- `config.py`: Configuration constants and action mappings
- `video_player.py`: Video playback thread
- `gui_component.py`: User interface components
- `action_tracker.py`: Tracks which actions are active at which frames
- `csv_handler.py`: Reads and writes CSV files
- `video_processor.py`: Creates output video with annotations

## Requirements

- Python 3.7+
- OpenCV (cv2)
- PyQt5
- pandas
- numpy

## Development

To extend the application, you can:

- Add new action types in `config.py`
- Modify the UI layout in `gui_component.py`
- Enhance video processing effects in `video_processor.py`
- Add new data analysis features to `csv_handler.py`
