# mid_face_features.py (Refactored to use _extract_base_au_features)

import numpy as np
import pandas as pd
import logging
import os
import joblib

# Use central config and utils
from paralysis_config import ZONE_CONFIG  # For zone-specific details
from paralysis_utils import _extract_base_au_features, calculate_ratio, calculate_percent_diff  # Import helpers

logger = logging.getLogger(__name__)
ZONE = 'mid'  # Define zone for this file


# extract_features function (MID FACE - Training)
def extract_features(df, side, zone_specific_config):
    """ Extracts features for MID FACE training using the helper and adding custom ones. """
    zone_name = zone_specific_config.get('name', 'Mid Face')
    actions = zone_specific_config.get('actions', [])
    aus = zone_specific_config.get('aus', [])
    feature_cfg = zone_specific_config.get('feature_extraction', {})
    min_val_cfg = feature_cfg.get('min_value', 0.0001)

    logger.debug(f"[{zone_name}] Extracting features for {side} side (Training)...")

    base_features_df = _extract_base_au_features(df, side, actions, aus, feature_cfg, zone_name)
    feature_data = base_features_df.to_dict('series')

    # 2. ET/ES Ratio Features (MID FACE SPECIFIC)
    percent_diff_cap_val = feature_cfg.get('percent_diff_cap', 200.0)
    for au_str_loop in aus:  # Use aus from config
        action_et = 'ET';
        action_es = 'ES'
        et_val_side = feature_data.get(f"{action_et}_{au_str_loop}_val_side")
        es_val_side = feature_data.get(f"{action_es}_{au_str_loop}_val_side")
        et_val_opp = feature_data.get(f"{action_et}_{au_str_loop}_val_opp")
        es_val_opp = feature_data.get(f"{action_es}_{au_str_loop}_val_opp")

        if all(isinstance(s, pd.Series) for s in [et_val_side, es_val_side, et_val_opp, es_val_opp]):
            ratio_side = calculate_ratio(et_val_side, es_val_side, min_value=min_val_cfg)
            ratio_opp = calculate_ratio(et_val_opp, es_val_opp, min_value=min_val_cfg)
            feature_data[f"{au_str_loop}_ETES_Ratio_Side"] = ratio_side
            feature_data[f"{au_str_loop}_ETES_Ratio_Opp"] = ratio_opp

            # ETES asymmetry features
            feature_data[f"{au_str_loop}_ETES_Asym_Diff"] = ratio_side - ratio_opp
            feature_data[f"{au_str_loop}_ETES_Asym_Ratio"] = calculate_ratio(ratio_side, ratio_opp, min_value=min_val_cfg)
            feature_data[f"{au_str_loop}_ETES_Asym_PercDiff"] = calculate_percent_diff(ratio_side, ratio_opp, min_value=min_val_cfg, cap=percent_diff_cap_val)
            feature_data[f"{au_str_loop}_ETES_Is_Weaker_Side"] = (ratio_side < ratio_opp).astype(int)
        else:  # Add defaults if any component is missing
            logger.debug(
                f"[{zone_name}] Missing ES/ET values for AU {au_str_loop} on side {side}. Using default ET/ES ratio features.")
            feature_data[f"{au_str_loop}_ETES_Ratio_Side"] = pd.Series(1.0, index=df.index)
            feature_data[f"{au_str_loop}_ETES_Ratio_Opp"] = pd.Series(1.0, index=df.index)
            feature_data[f"{au_str_loop}_ETES_Asym_Diff"] = pd.Series(0.0, index=df.index)
            feature_data[f"{au_str_loop}_ETES_Asym_Ratio"] = pd.Series(1.0, index=df.index)
            feature_data[f"{au_str_loop}_ETES_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
            feature_data[f"{au_str_loop}_ETES_Is_Weaker_Side"] = pd.Series(0, index=df.index)

    # 3. Interaction/Summary Features (MID FACE SPECIFIC)
    es_au45_val_side = feature_data.get('ES_AU45_r_val_side', pd.Series(0.0, index=df.index))
    et_au45_val_side = feature_data.get('ET_AU45_r_val_side', pd.Series(0.0, index=df.index))
    es_au07_val_side = feature_data.get('ES_AU07_r_val_side', pd.Series(0.0, index=df.index))
    et_au07_val_side = feature_data.get('ET_AU07_r_val_side', pd.Series(0.0, index=df.index))

    feature_data['ES_ET_AU45_ratio_side'] = calculate_ratio(es_au45_val_side, et_au45_val_side, min_value=min_val_cfg)
    feature_data['ET_ES_AU45_diff_side'] = (et_au45_val_side - es_au45_val_side).abs()
    feature_data['ES_ET_AU07_ratio_side'] = calculate_ratio(es_au07_val_side, et_au07_val_side, min_value=min_val_cfg)
    feature_data['ET_ES_AU07_diff_side'] = (et_au07_val_side - es_au07_val_side).abs()

    # NEW: AU45 × AU06 interactions for each action (lagophthalmos and eyelid synergy)
    for action in actions:
        au45_val_side = feature_data.get(f'{action}_AU45_r_val_side', pd.Series(0.0, index=df.index))
        au06_val_side = feature_data.get(f'{action}_AU06_r_val_side', pd.Series(0.0, index=df.index))
        au45_val_opp = feature_data.get(f'{action}_AU45_r_val_opp', pd.Series(0.0, index=df.index))
        au06_val_opp = feature_data.get(f'{action}_AU06_r_val_opp', pd.Series(0.0, index=df.index))

        # Product and ratio (captures eyelid closure synergy)
        feature_data[f'{action}_AU45_AU06_product_side'] = au45_val_side * au06_val_side
        feature_data[f'{action}_AU45_AU06_ratio_side'] = calculate_ratio(au45_val_side, au06_val_side, min_value=min_val_cfg)

        # Asymmetry of product (different synergy patterns left vs right)
        product_side = au45_val_side * au06_val_side
        product_opp = au45_val_opp * au06_val_opp
        feature_data[f'{action}_AU45_AU06_product_asym'] = product_side - product_opp

    # BK-specific asymmetry (blink asymmetry is critical for lagophthalmos detection)
    bk_au45_asym_diff = feature_data.get('BK_AU45_r_Asym_Diff', pd.Series(0.0, index=df.index))
    feature_data['BK_AU45_strong_asymmetry'] = (bk_au45_asym_diff.abs() > 0.5).astype(int)

    # AU06 dominance indicator (which muscle contributes more to eye closure)
    es_au06_val = feature_data.get('ES_AU06_r_val_side', pd.Series(0.0, index=df.index))
    es_au45_val = feature_data.get('ES_AU45_r_val_side', pd.Series(0.0, index=df.index))
    feature_data['ES_AU06_dominant'] = (es_au06_val > es_au45_val).astype(int)

    for au_base_str in aus:  # Use aus from config
        val_side_cols = [f"{act}_{au_base_str}_val_side" for act in actions if
                         f"{act}_{au_base_str}_val_side" in feature_data]
        if val_side_cols:
            all_series = [pd.to_numeric(feature_data[col], errors='coerce').fillna(0) for col in val_side_cols]
            if all_series:  # Check if list is not empty
                try:
                    stacked_vals = np.stack([s.to_numpy() for s in all_series], axis=1)
                    max_vals = np.max(stacked_vals, axis=1);
                    min_vals_agg = np.min(stacked_vals, axis=1)  # Renamed min_vals
                    feature_data[f"max_{au_base_str}_val_side"] = pd.Series(max_vals, index=df.index)
                    feature_data[f"min_{au_base_str}_val_side"] = pd.Series(min_vals_agg, index=df.index)
                    feature_data[f"range_{au_base_str}_val_side"] = pd.Series(max_vals - min_vals_agg, index=df.index)
                except ValueError as e:  # Catch errors if stacking empty arrays
                    logger.debug(
                        f"[{zone_name}] Stacking error for {au_base_str} value (side: {side}): {e}. Defaulting features.");
                    feature_data[f"max_{au_base_str}_val_side"] = pd.Series(0.0, index=df.index)
                    feature_data[f"min_{au_base_str}_val_side"] = pd.Series(0.0, index=df.index)
                    feature_data[f"range_{au_base_str}_val_side"] = pd.Series(0.0, index=df.index)
            else:  # Add default series if no valid columns found
                feature_data[f"max_{au_base_str}_val_side"] = pd.Series(0.0, index=df.index)
                feature_data[f"min_{au_base_str}_val_side"] = pd.Series(0.0, index=df.index)
                feature_data[f"range_{au_base_str}_val_side"] = pd.Series(0.0, index=df.index)

        # Summary for _Asym_PercDiff
        pd_cols = [f"{act}_{au_base_str}_Asym_PercDiff" for act in actions if
                  f"{act}_{au_base_str}_Asym_PercDiff" in feature_data]
        if pd_cols:
            pd_series_list = [pd.to_numeric(feature_data[col], errors='coerce').fillna(0) for col in pd_cols]
            if pd_series_list:
                try:
                    pd_stacked = np.stack([s.to_numpy() for s in pd_series_list], axis=1)
                    feature_data[f"max_{au_base_str}_Asym_PercDiff"] = pd.Series(np.max(pd_stacked, axis=1), index=df.index)
                    feature_data[f"min_{au_base_str}_Asym_PercDiff"] = pd.Series(np.min(pd_stacked, axis=1), index=df.index)
                    feature_data[f"range_{au_base_str}_Asym_PercDiff"] = pd.Series(np.max(pd_stacked, axis=1) - np.min(pd_stacked, axis=1), index=df.index)
                except ValueError as e:
                    logger.debug(f"[{zone_name}] Stacking error for {au_base_str} Asym_PercDiff: {e}. Defaulting.")
                    feature_data[f"max_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
                    feature_data[f"min_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
                    feature_data[f"range_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
            else:
                feature_data[f"max_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
                feature_data[f"min_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
                feature_data[f"range_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
        else:
            feature_data[f"max_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
            feature_data[f"min_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)
            feature_data[f"range_{au_base_str}_Asym_PercDiff"] = pd.Series(0.0, index=df.index)

        # Summary for _Asym_Ratio
        ratio_cols = [f"{act}_{au_base_str}_Asym_Ratio" for act in actions if
                     f"{act}_{au_base_str}_Asym_Ratio" in feature_data]
        if ratio_cols:
            ratio_series_list = [pd.to_numeric(feature_data[col], errors='coerce').fillna(1) for col in ratio_cols]
            if ratio_series_list:
                try:
                    ratio_stacked = np.stack([s.to_numpy() for s in ratio_series_list], axis=1)
                    feature_data[f"max_{au_base_str}_Asym_Ratio"] = pd.Series(np.max(ratio_stacked, axis=1), index=df.index)
                    feature_data[f"min_{au_base_str}_Asym_Ratio"] = pd.Series(np.min(ratio_stacked, axis=1), index=df.index)
                    feature_data[f"range_{au_base_str}_Asym_Ratio"] = pd.Series(np.max(ratio_stacked, axis=1) - np.min(ratio_stacked, axis=1), index=df.index)
                except ValueError as e:
                    logger.debug(f"[{zone_name}] Stacking error for {au_base_str} Asym_Ratio: {e}. Defaulting.")
                    feature_data[f"max_{au_base_str}_Asym_Ratio"] = pd.Series(1.0, index=df.index)
                    feature_data[f"min_{au_base_str}_Asym_Ratio"] = pd.Series(1.0, index=df.index)
                    feature_data[f"range_{au_base_str}_Asym_Ratio"] = pd.Series(0.0, index=df.index)
            else:
                feature_data[f"max_{au_base_str}_Asym_Ratio"] = pd.Series(1.0, index=df.index)
                feature_data[f"min_{au_base_str}_Asym_Ratio"] = pd.Series(1.0, index=df.index)
                feature_data[f"range_{au_base_str}_Asym_Ratio"] = pd.Series(0.0, index=df.index)
        else:
            feature_data[f"max_{au_base_str}_Asym_Ratio"] = pd.Series(1.0, index=df.index)
            feature_data[f"min_{au_base_str}_Asym_Ratio"] = pd.Series(1.0, index=df.index)
            feature_data[f"range_{au_base_str}_Asym_Ratio"] = pd.Series(0.0, index=df.index)

    features_df_final = pd.DataFrame(feature_data, index=df.index)
    logger.debug(f"[{zone_name}] Generated {features_df_final.shape[1]} features for {side} (Training).")
    return features_df_final


# extract_features_for_detection (MID FACE - Detection) - Needs similar refactoring
def extract_features_for_detection(row_data, side, zone_key_for_detection):
    # This function will also call _extract_base_au_features
    # and then add its specific summary/interaction features for a single row.
    # (Implementation similar to lower_face_features.py's detection function, but with mid-face specific summaries)
    try:
        from paralysis_config import ZONE_CONFIG as global_zone_config  # Ensure it's accessible
        det_config = global_zone_config[zone_key_for_detection]
        det_feature_cfg = det_config.get('feature_extraction', {})
        det_actions = det_config.get('actions', [])
        det_aus = det_config.get('aus', [])
        det_filenames = det_config.get('filenames', {})
        det_zone_name = det_config.get('name', zone_key_for_detection.capitalize() + ' Face')
        min_val_cfg_det = det_feature_cfg.get('min_value', 0.0001)
        percent_diff_cap_val = det_feature_cfg.get('percent_diff_cap', 200.0)

    except KeyError:
        logger.error(f"Config for requested zone '{zone_key_for_detection}' not found in detection. Cannot proceed.")
        return None

    feature_list_path = det_filenames.get('feature_list')
    if not feature_list_path or not os.path.exists(feature_list_path):
        logger.error(f"[{det_zone_name}] Feature list not found. Cannot extract detection features.")
        return None
    try:
        # Handle both .pkl and .list text files
        if feature_list_path.endswith('.list'):
            with open(feature_list_path, 'r') as f:
                ordered_feature_names = [line.strip() for line in f if line.strip()]
        else:
            ordered_feature_names = joblib.load(feature_list_path)
    except Exception as e:
        logger.error(f"[{det_zone_name}] Failed load feature list: {e}"); return None

    if isinstance(row_data, dict):
        df_single_row = pd.DataFrame([row_data], index=[0])
    elif isinstance(row_data, pd.Series):
        df_single_row = pd.DataFrame([row_data.to_dict()], index=[0])
    else:
        logger.error(f"[{det_zone_name}] Invalid row_data type: {type(row_data)}"); return None

    base_features_df_det = _extract_base_au_features(df_single_row, side, det_actions, det_aus, det_feature_cfg,
                                                     det_zone_name)
    feature_data_det = base_features_df_det.to_dict('series')

    # ET/ES Ratio Features for detection
    for au_str_loop_det in det_aus:
        action_et = 'ET';
        action_es = 'ES'
        et_val_side_det = feature_data_det.get(f"{action_et}_{au_str_loop_det}_val_side", pd.Series([0.0]))
        es_val_side_det = feature_data_det.get(f"{action_es}_{au_str_loop_det}_val_side", pd.Series([0.0]))
        et_val_opp_det = feature_data_det.get(f"{action_et}_{au_str_loop_det}_val_opp", pd.Series([0.0]))
        es_val_opp_det = feature_data_det.get(f"{action_es}_{au_str_loop_det}_val_opp", pd.Series([0.0]))

        if all(isinstance(s, pd.Series) and not s.empty for s in [et_val_side_det, es_val_side_det, et_val_opp_det, es_val_opp_det]):
            ratio_side = calculate_ratio(et_val_side_det, es_val_side_det, min_value=min_val_cfg_det)
            ratio_opp = calculate_ratio(et_val_opp_det, es_val_opp_det, min_value=min_val_cfg_det)
            feature_data_det[f"{au_str_loop_det}_ETES_Ratio_Side"] = ratio_side
            feature_data_det[f"{au_str_loop_det}_ETES_Ratio_Opp"] = ratio_opp

            # ETES asymmetry features
            ratio_side_val = ratio_side.iloc[0] if isinstance(ratio_side, pd.Series) else ratio_side
            ratio_opp_val = ratio_opp.iloc[0] if isinstance(ratio_opp, pd.Series) else ratio_opp
            feature_data_det[f"{au_str_loop_det}_ETES_Asym_Diff"] = pd.Series([ratio_side_val - ratio_opp_val])
            feature_data_det[f"{au_str_loop_det}_ETES_Asym_Ratio"] = calculate_ratio(ratio_side, ratio_opp, min_value=min_val_cfg_det)
            feature_data_det[f"{au_str_loop_det}_ETES_Asym_PercDiff"] = calculate_percent_diff(ratio_side, ratio_opp, min_value=min_val_cfg_det, cap=percent_diff_cap_val)
            feature_data_det[f"{au_str_loop_det}_ETES_Is_Weaker_Side"] = pd.Series([1 if ratio_side_val < ratio_opp_val else 0])
        else:
            # Add defaults if any component is missing
            feature_data_det[f"{au_str_loop_det}_ETES_Ratio_Side"] = pd.Series([1.0])
            feature_data_det[f"{au_str_loop_det}_ETES_Ratio_Opp"] = pd.Series([1.0])
            feature_data_det[f"{au_str_loop_det}_ETES_Asym_Diff"] = pd.Series([0.0])
            feature_data_det[f"{au_str_loop_det}_ETES_Asym_Ratio"] = pd.Series([1.0])
            feature_data_det[f"{au_str_loop_det}_ETES_Asym_PercDiff"] = pd.Series([0.0])
            feature_data_det[f"{au_str_loop_det}_ETES_Is_Weaker_Side"] = pd.Series([0])

    # Interaction/Summary Features for detection
    es_au45_s = feature_data_det.get('ES_AU45_r_val_side', pd.Series([0.0]))
    et_au45_s = feature_data_det.get('ET_AU45_r_val_side', pd.Series([0.0]))
    es_au07_s = feature_data_det.get('ES_AU07_r_val_side', pd.Series([0.0]))
    et_au07_s = feature_data_det.get('ET_AU07_r_val_side', pd.Series([0.0]))

    feature_data_det['ES_ET_AU45_ratio_side'] = calculate_ratio(es_au45_s, et_au45_s, min_value=min_val_cfg_det)
    feature_data_det['ET_ES_AU45_diff_side'] = pd.Series([abs(et_au45_s.iloc[0] - es_au45_s.iloc[0])])
    feature_data_det['ES_ET_AU07_ratio_side'] = calculate_ratio(es_au07_s, et_au07_s, min_value=min_val_cfg_det)
    feature_data_det['ET_ES_AU07_diff_side'] = pd.Series([abs(et_au07_s.iloc[0] - es_au07_s.iloc[0])])

    # NEW: AU45 × AU06 interactions for each action (detection)
    for action_det in det_actions:
        au45_val_side_s = feature_data_det.get(f'{action_det}_AU45_r_val_side', pd.Series([0.0]))
        au06_val_side_s = feature_data_det.get(f'{action_det}_AU06_r_val_side', pd.Series([0.0]))
        au45_val_opp_s = feature_data_det.get(f'{action_det}_AU45_r_val_opp', pd.Series([0.0]))
        au06_val_opp_s = feature_data_det.get(f'{action_det}_AU06_r_val_opp', pd.Series([0.0]))

        au45_val_side_val = au45_val_side_s.iloc[0] if isinstance(au45_val_side_s, pd.Series) and not au45_val_side_s.empty else 0.0
        au06_val_side_val = au06_val_side_s.iloc[0] if isinstance(au06_val_side_s, pd.Series) and not au06_val_side_s.empty else 0.0
        au45_val_opp_val = au45_val_opp_s.iloc[0] if isinstance(au45_val_opp_s, pd.Series) and not au45_val_opp_s.empty else 0.0
        au06_val_opp_val = au06_val_opp_s.iloc[0] if isinstance(au06_val_opp_s, pd.Series) and not au06_val_opp_s.empty else 0.0

        # Product and ratio
        feature_data_det[f'{action_det}_AU45_AU06_product_side'] = pd.Series([au45_val_side_val * au06_val_side_val])
        feature_data_det[f'{action_det}_AU45_AU06_ratio_side'] = calculate_ratio(
            pd.Series([au45_val_side_val]), pd.Series([au06_val_side_val]), min_value=min_val_cfg_det
        )

        # Asymmetry of product
        product_side_val = au45_val_side_val * au06_val_side_val
        product_opp_val = au45_val_opp_val * au06_val_opp_val
        feature_data_det[f'{action_det}_AU45_AU06_product_asym'] = pd.Series([product_side_val - product_opp_val])

    # BK-specific asymmetry (detection)
    bk_au45_asym_diff_s = feature_data_det.get('BK_AU45_r_Asym_Diff', pd.Series([0.0]))
    bk_au45_asym_diff_val = bk_au45_asym_diff_s.iloc[0] if isinstance(bk_au45_asym_diff_s, pd.Series) and not bk_au45_asym_diff_s.empty else 0.0
    feature_data_det['BK_AU45_strong_asymmetry'] = pd.Series([1 if abs(bk_au45_asym_diff_val) > 0.5 else 0])

    # AU06 dominance indicator (detection)
    es_au06_s = feature_data_det.get('ES_AU06_r_val_side', pd.Series([0.0]))
    es_au45_det_s = feature_data_det.get('ES_AU45_r_val_side', pd.Series([0.0]))
    es_au06_val = es_au06_s.iloc[0] if isinstance(es_au06_s, pd.Series) and not es_au06_s.empty else 0.0
    es_au45_det_val = es_au45_det_s.iloc[0] if isinstance(es_au45_det_s, pd.Series) and not es_au45_det_s.empty else 0.0
    feature_data_det['ES_AU06_dominant'] = pd.Series([1 if es_au06_val > es_au45_det_val else 0])

    # Summary features (max, min, range) for each AU across actions
    for au_base_str_det in det_aus:
        # val_side summary
        val_side_cols_det = [f"{act}_{au_base_str_det}_val_side" for act in det_actions
                             if f"{act}_{au_base_str_det}_val_side" in feature_data_det]
        if val_side_cols_det:
            vals_list = [feature_data_det[col].iloc[0] if isinstance(feature_data_det[col], pd.Series) and not feature_data_det[col].empty
                        else 0.0 for col in val_side_cols_det]
            feature_data_det[f"max_{au_base_str_det}_val_side"] = pd.Series([max(vals_list) if vals_list else 0.0])
            feature_data_det[f"min_{au_base_str_det}_val_side"] = pd.Series([min(vals_list) if vals_list else 0.0])
            feature_data_det[f"range_{au_base_str_det}_val_side"] = pd.Series([max(vals_list) - min(vals_list) if vals_list else 0.0])
        else:
            feature_data_det[f"max_{au_base_str_det}_val_side"] = pd.Series([0.0])
            feature_data_det[f"min_{au_base_str_det}_val_side"] = pd.Series([0.0])
            feature_data_det[f"range_{au_base_str_det}_val_side"] = pd.Series([0.0])

        # Asym_PercDiff summary
        pd_cols_det = [f"{act}_{au_base_str_det}_Asym_PercDiff" for act in det_actions
                      if f"{act}_{au_base_str_det}_Asym_PercDiff" in feature_data_det]
        if pd_cols_det:
            pd_vals_list = [feature_data_det[col].iloc[0] if isinstance(feature_data_det[col], pd.Series) and not feature_data_det[col].empty
                           else 0.0 for col in pd_cols_det]
            feature_data_det[f"max_{au_base_str_det}_Asym_PercDiff"] = pd.Series([max(pd_vals_list) if pd_vals_list else 0.0])
            feature_data_det[f"min_{au_base_str_det}_Asym_PercDiff"] = pd.Series([min(pd_vals_list) if pd_vals_list else 0.0])
            feature_data_det[f"range_{au_base_str_det}_Asym_PercDiff"] = pd.Series([max(pd_vals_list) - min(pd_vals_list) if pd_vals_list else 0.0])
        else:
            feature_data_det[f"max_{au_base_str_det}_Asym_PercDiff"] = pd.Series([0.0])
            feature_data_det[f"min_{au_base_str_det}_Asym_PercDiff"] = pd.Series([0.0])
            feature_data_det[f"range_{au_base_str_det}_Asym_PercDiff"] = pd.Series([0.0])

        # Asym_Ratio summary
        ratio_cols_det = [f"{act}_{au_base_str_det}_Asym_Ratio" for act in det_actions
                         if f"{act}_{au_base_str_det}_Asym_Ratio" in feature_data_det]
        if ratio_cols_det:
            ratio_vals_list = [feature_data_det[col].iloc[0] if isinstance(feature_data_det[col], pd.Series) and not feature_data_det[col].empty
                              else 1.0 for col in ratio_cols_det]
            feature_data_det[f"max_{au_base_str_det}_Asym_Ratio"] = pd.Series([max(ratio_vals_list) if ratio_vals_list else 1.0])
            feature_data_det[f"min_{au_base_str_det}_Asym_Ratio"] = pd.Series([min(ratio_vals_list) if ratio_vals_list else 1.0])
            feature_data_det[f"range_{au_base_str_det}_Asym_Ratio"] = pd.Series([max(ratio_vals_list) - min(ratio_vals_list) if ratio_vals_list else 0.0])
        else:
            feature_data_det[f"max_{au_base_str_det}_Asym_Ratio"] = pd.Series([1.0])
            feature_data_det[f"min_{au_base_str_det}_Asym_Ratio"] = pd.Series([1.0])
            feature_data_det[f"range_{au_base_str_det}_Asym_Ratio"] = pd.Series([0.0])

    feature_data_det["side_indicator"] = pd.Series([0 if side.lower() == 'left' else 1])

    feature_dict_final_det = {k: v.iloc[0] for k, v in feature_data_det.items() if
                              isinstance(v, pd.Series) and not v.empty}
    # ... (final assembly into feature_vector as in lower_face_features.py) ...
    feature_vector = []
    for name in ordered_feature_names:
        value = feature_dict_final_det.get(name, 0.0)  # Default to 0.0 if missing
        try:
            val_float = float(value)
            feature_vector.append(0.0 if np.isnan(val_float) else val_float)
        except (ValueError, TypeError):
            feature_vector.append(0.0)
    return feature_vector