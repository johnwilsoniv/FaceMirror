#!/usr/bin/env python3
"""
Performance Test: Full Python Pipeline vs. C++ Hybrid

This script tests the end-to-end performance of the full Python AU pipeline
and compares it to the hybrid C++/Python approach.

Expected findings:
- C++ hybrid: 99.24% time in C++ binary (34.97s per 50 frames)
- Full Python: All processing in Python/ONNX (should be MUCH faster!)

Key difference: No more 35-second C++ binary bottleneck!
"""

import time
import numpy as np
from pathlib import Path

print("=" * 80)
print("FULL PYTHON PIPELINE PERFORMANCE TEST")
print("=" * 80)
print("")

# Test configuration
test_video = "/Users/johnwilsoniv/Documents/SplitFace/S1O Processed Files/Face Mirror 1.0 Output/IMG_0942_left_mirrored.mp4"
test_frames = 10  # Test on first 10 frames for quick comparison

if not Path(test_video).exists():
    print(f"‚ùå Test video not found: {test_video}")
    print("Please provide a valid test video")
    exit(1)

print(f"Test video: {Path(test_video).name}")
print(f"Processing: {test_frames} frames")
print("")

# Import after config so we see any import timing
print("Loading full Python pipeline...")
start_import = time.time()

try:
    from full_python_au_pipeline import FullPythonAUPipeline
except ImportError as e:
    print(f"‚ùå Failed to import pipeline: {e}")
    print("Make sure all dependencies are installed")
    exit(1)

import_time = time.time() - start_import
print(f"‚úì Pipeline imported in {import_time:.2f}s")
print("")

# Initialize pipeline
print("Initializing pipeline components...")
print("-" * 80)

start_init = time.time()

try:
    pipeline = FullPythonAUPipeline(
        retinaface_model='weights/retinaface_mobilenet025_coreml.onnx',
        pfld_model='weights/pfld_cunjian.onnx',
        pdm_file='In-the-wild_aligned_PDM_68.txt',  # In root directory
        au_models_dir='/Users/johnwilsoniv/repo/fea_tool/external_libs/openFace/OpenFace/lib/local/FaceAnalyser/AU_predictors',
        triangulation_file='tris_68_full.txt',  # In root directory
        use_calc_params=True,  # Use full CalcParams (99.45% accuracy)
        verbose=True  # Now using CPU mode (CoreML disabled in pipeline)
    )
except Exception as e:
    print(f"‚ùå Failed to initialize pipeline: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

init_time = time.time() - start_init
print("")
print(f"‚úì Initialization complete in {init_time:.2f}s")
print("")

# Process video
print("=" * 80)
print(f"PROCESSING {test_frames} FRAMES")
print("=" * 80)
print("")

start_process = time.time()

try:
    results = pipeline.process_video(
        video_path=test_video,
        output_csv=None,  # Don't save (just testing)
        max_frames=test_frames
    )
except Exception as e:
    print(f"‚ùå Processing failed: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

process_time = time.time() - start_process

# Analyze results
success_count = results['success'].sum()
fail_count = len(results) - success_count

print("")
print("=" * 80)
print("PERFORMANCE RESULTS")
print("=" * 80)
print("")

print(f"Frames processed: {len(results)}")
print(f"  Success: {success_count}")
print(f"  Failed: {fail_count}")
print(f"  Success rate: {success_count/len(results)*100:.1f}%")
print("")

print("Timing Breakdown:")
print(f"  Import time:     {import_time:.3f}s")
print(f"  Init time:       {init_time:.3f}s")
print(f"  Processing time: {process_time:.3f}s")
print(f"  Total time:      {import_time + init_time + process_time:.3f}s")
print("")

# Per-frame metrics
ms_per_frame = (process_time / len(results)) * 1000
fps = len(results) / process_time

print("Per-Frame Performance:")
print(f"  Time per frame: {ms_per_frame:.2f}ms")
print(f"  Throughput:     {fps:.2f} FPS")
print("")

# Extrapolate to 60-second video
video_fps = 30  # Assume 30 FPS
frames_60s = video_fps * 60
estimated_60s = (frames_60s * ms_per_frame) / 1000

print(f"Estimated for 60-second video (1800 frames @ 30 FPS):")
print(f"  Processing time: {estimated_60s:.1f}s ({estimated_60s/60:.1f} minutes)")
print(f"  Speedup vs realtime: {60/estimated_60s:.2f}x")
print("")

# Compare to hybrid approach (from profiling results)
print("=" * 80)
print("COMPARISON: Full Python vs. C++ Hybrid")
print("=" * 80)
print("")

# From previous profiling (50 frames)
hybrid_cpp_time = 34.97  # C++ binary time
hybrid_python_time = 0.27  # Python processing time
hybrid_total = hybrid_cpp_time + hybrid_python_time
hybrid_per_frame = (hybrid_total / 50) * 1000

print("C++ Hybrid Pipeline (50 frames):")
print(f"  C++ binary:       34.97s (99.24%)")
print(f"  Python AU pred:    0.27s (0.76%)")
print(f"  Total:           35.24s")
print(f"  Per frame:       {hybrid_per_frame:.2f}ms")
print("")

print(f"Full Python Pipeline ({test_frames} frames):")
print(f"  Total:           {process_time:.2f}s (100% Python/ONNX)")
print(f"  Per frame:       {ms_per_frame:.2f}ms")
print("")

# Calculate speedup
if hybrid_per_frame > 0:
    speedup = hybrid_per_frame / ms_per_frame
    print(f"üöÄ SPEEDUP: {speedup:.1f}x faster than hybrid!")
    print("")

    if speedup > 1:
        print(f"‚úÖ Full Python pipeline is FASTER by removing C++ bottleneck!")
    else:
        print(f"‚ö†Ô∏è  Full Python pipeline is slower (expected for face detection)")
    print("")

# Component breakdown estimate
print("Estimated Component Breakdown (Full Python):")
print(f"  Face Detection:       ~{ms_per_frame * 0.30:.1f}ms (30%)")
print(f"  Landmark Detection:   ~{ms_per_frame * 0.15:.1f}ms (15%)")
print(f"  CalcParams:          ~{ms_per_frame * 0.10:.1f}ms (10%)")
print(f"  Face Alignment:       ~{ms_per_frame * 0.15:.1f}ms (15%)")
print(f"  HOG Extraction:       ~{ms_per_frame * 0.20:.1f}ms (20%)")
print(f"  Running Median:       ~{ms_per_frame * 0.01:.1f}ms (1%) [Cython!]")
print(f"  AU Prediction:        ~{ms_per_frame * 0.09:.1f}ms (9%)")
print("")

# Show some AU results
if success_count > 0:
    print("=" * 80)
    print("SAMPLE AU PREDICTIONS")
    print("=" * 80)
    print("")

    success_frames = results[results['success'] == True]
    au_cols = [col for col in results.columns if col.startswith('AU') and col.endswith('_r')]

    if len(au_cols) > 0 and len(success_frames) > 0:
        print(f"First successful frame (frame {success_frames.iloc[0]['frame']}):")
        for au_col in sorted(au_cols):
            val = success_frames.iloc[0][au_col]
            print(f"  {au_col}: {val:.3f}")
        print("")

        print("AU Statistics (all successful frames):")
        for au_col in sorted(au_cols):
            mean_val = success_frames[au_col].mean()
            max_val = success_frames[au_col].max()
            print(f"  {au_col}: mean={mean_val:.3f}, max={max_val:.3f}")

print("")
print("=" * 80)
print("TEST COMPLETE")
print("=" * 80)
print("")

# Summary
print("KEY FINDINGS:")
print("")
if speedup > 1:
    print(f"‚úÖ Full Python pipeline is {speedup:.1f}x FASTER")
    print(f"   Eliminated 99.24% bottleneck (C++ binary)")
    print(f"   All processing now in Python/ONNX/Cython")
else:
    print(f"‚ö†Ô∏è  Full Python pipeline is {1/speedup:.1f}x slower")
    print(f"   Face detection + landmarks are slower than C++ CLNF")
    print(f"   But: More portable, easier to distribute!")

print("")
print("ADVANTAGES of Full Python:")
print("  ‚úÖ 100% Python (no C++ dependencies)")
print("  ‚úÖ Cross-platform (Windows, Mac, Linux)")
print("  ‚úÖ CalcParams 99.45% accuracy (gold standard)")
print("  ‚úÖ Running median 260x faster (Cython)")
print("  ‚úÖ No intermediate files (processes in memory)")
print("  ‚úÖ PyInstaller friendly")
print("")
