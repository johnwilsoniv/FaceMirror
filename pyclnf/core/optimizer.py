"""
NU-RLMS Optimizer - Parameter optimization for CLNF

Implements the Normalized Unconstrained Regularized Least Mean Squares optimizer
used in OpenFace CLNF for fitting the Point Distribution Model to detected landmarks.

The optimizer minimizes:
    E(p) = ||v - J·Δp||² + λ||Λ^(-1/2)·Δp||²

Where:
    - p: Current parameter vector [scale, tx, ty, wx, wy, wz, q0, ..., qm]
    - Δp: Parameter update
    - v: Mean-shift vector (from patch expert responses)
    - J: Jacobian matrix (∂landmarks/∂params)
    - λ: Regularization weight
    - Λ: Diagonal matrix of parameter variances (eigenvalues for shape params)

Update rule:
    Δp = (J^T·W·J + λ·Λ^(-1))^(-1) · (J^T·W·v - λ·Λ^(-1)·p)

Where W is a diagonal weight matrix (typically identity for uniform weighting).
"""

import numpy as np
from typing import Tuple, Optional
import cv2

from .utils import align_shapes_with_scale, apply_similarity_transform, invert_similarity_transform


class NURLMSOptimizer:
    """
    NU-RLMS optimizer for CLNF parameter estimation.

    This optimizer iteratively refines the PDM parameters to fit detected landmarks
    using patch expert responses and shape model constraints.
    """

    def __init__(self,
                 regularization: float = 1.0,
                 max_iterations: int = 10,
                 convergence_threshold: float = 0.01,
                 sigma: float = 1.75,
                 weight_multiplier: float = 5.0,
                 debug_mode: bool = False,
                 tracked_landmarks: list = None):
        """
        Initialize NU-RLMS optimizer.

        Args:
            regularization: Regularization weight λ (higher = stronger shape prior)
            max_iterations: Maximum optimization iterations
            convergence_threshold: Convergence threshold for parameter change
            sigma: Gaussian kernel sigma for KDE mean-shift (OpenFace default: 1.75)
            weight_multiplier: Weight multiplier w for patch confidences
                             (OpenFace uses w=7 for Multi-PIE, w=5 for in-the-wild)
                             Controls how much to trust patch responses vs shape prior
            debug_mode: Enable detailed debug output (similar to MTCNN debug mode)
            tracked_landmarks: Landmarks to track in detail when debug_mode=True (default: [36, 48, 30, 8])
        """
        self.regularization = regularization
        self.max_iterations = max_iterations
        self.convergence_threshold = convergence_threshold
        self.sigma = sigma
        self.weight_multiplier = weight_multiplier
        self.kde_cache = {}  # Cache for precomputed KDE kernels
        self.debug_mode = debug_mode
        self.tracked_landmarks = tracked_landmarks if tracked_landmarks is not None else [36, 48, 30, 8]

    def optimize(self,
                 pdm,
                 initial_params: np.ndarray,
                 patch_experts: dict,
                 image: np.ndarray,
                 weights: Optional[np.ndarray] = None,
                 window_size: int = 11,
                 patch_scaling: float = 0.25,
                 sigma_components: dict = None) -> Tuple[np.ndarray, dict]:
        """
        Optimize PDM parameters to fit landmarks to image.

        Args:
            pdm: PDM instance with compute_jacobian and params_to_landmarks methods
            initial_params: Initial parameter guess [s, tx, ty, wx, wy, wz, q...]
            patch_experts: Dict mapping landmark_idx -> CCNFPatchExpert
            image: Grayscale image to fit to
            weights: Optional per-landmark weights (default: uniform)
            window_size: Search window size for mean-shift (default: 11)
            patch_scaling: Scale at which patches were trained (0.25, 0.35, or 0.5)
                          Used to create reference shape for warping

        Returns:
            optimized_params: Optimized parameter vector
            info: Dictionary with optimization info (iterations, convergence, etc.)
        """
        params = initial_params.copy()
        n_params = len(params)
        n_landmarks = pdm.n_points

        # Initialize weights (default: uniform)
        if weights is None:
            weights = np.ones(n_landmarks)

        # Create diagonal weight matrix W for 2D landmarks (2n × 2n)
        # OpenFace behavior (see PDM.cpp line 613 and LandmarkDetectorModel.cpp):
        # - weight_factor > 0: W = weight_factor · diag(patch_confidences)  [NU-RLMS mode]
        # - weight_factor = 0: W = Identity  [Video mode - all landmarks weighted equally]
        if self.weight_multiplier > 0:
            # NU-RLMS mode: apply weight multiplier to patch confidences
            W = self.weight_multiplier * np.diag(np.repeat(weights, 2))
        else:
            # Video mode: use identity matrix (all landmarks weighted equally)
            W = np.eye(n_landmarks * 2)

        # Create regularization matrix Λ^(-1)
        Lambda_inv = self._compute_lambda_inv(pdm, n_params)

        # Debug: Print initialization
        if self.debug_mode:
            init_landmarks = pdm.params_to_landmarks_2d(params)
            print(f"\n[PY][INIT] Initial parameters:")
            print(f"[PY][INIT]   params_local (first 5): {params[:5]}")
            print(f"[PY][INIT]   scale: {params[0]:.6f}")
            print(f"[PY][INIT]   rotation: ({params[1]:.6f}, {params[2]:.6f}, {params[3]:.6f})")
            print(f"[PY][INIT]   translation: ({params[4]:.6f}, {params[5]:.6f})")
            print(f"[PY][INIT] Initial tracked landmarks:")
            for lm_idx in self.tracked_landmarks:
                if lm_idx < len(init_landmarks):
                    print(f"[PY][INIT]   Landmark_{lm_idx}: ({init_landmarks[lm_idx][0]:.4f}, {init_landmarks[lm_idx][1]:.4f})")

        # =================================================================
        # STRUCTURE MATCHING C++ NU_RLMS (lines 1148-1278)
        # =================================================================

        # 1. Get initial landmark positions in IMAGE coordinates
        landmarks_2d_initial = pdm.params_to_landmarks_2d(params)

        # 2. Get REFERENCE shape at patch_scaling (canonical pose)
        reference_shape = pdm.get_reference_shape(patch_scaling, params[6:])

        # 3. Compute similarity transform: IMAGE ↔ REFERENCE
        from .utils import align_shapes_with_scale, invert_similarity_transform
        sim_img_to_ref = align_shapes_with_scale(landmarks_2d_initial, reference_shape)
        sim_ref_to_img = invert_similarity_transform(sim_img_to_ref)

        # 4. PRECOMPUTE response maps ONCE at initial positions (C++ line 798)
        # These are reused for ALL iterations in both rigid and non-rigid phases!
        response_maps = self._precompute_response_maps(
            landmarks_2d_initial, patch_experts, image, window_size,
            sim_img_to_ref, sim_ref_to_img, sigma_components, iteration=0
        )

        # Debug: Print initial landmarks
        if self.debug_mode:
            print(f"\n[PY][ITER0_WS{window_size}] Initial landmark positions:")
            for lm_idx in self.tracked_landmarks:
                if lm_idx < len(landmarks_2d_initial):
                    print(f"[PY][ITER0_WS{window_size}]   Landmark_{lm_idx}: ({landmarks_2d_initial[lm_idx][0]:.4f}, {landmarks_2d_initial[lm_idx][1]:.4f})")

        # =================================================================
        # PHASE 1: RIGID optimization with inner convergence loop
        # Matches OpenFace LandmarkDetectorModel.cpp:844 NU_RLMS(..., rigid=true)
        # =================================================================

        rigid_params = params.copy()
        base_landmarks_rigid = landmarks_2d_initial.copy()  # Base for rigid = initial
        previous_landmarks = None
        rigid_converged = False

        for rigid_iter in range(self.max_iterations):
            # Compute current shape from rigid params
            current_landmarks = pdm.params_to_landmarks_2d(rigid_params)

            # Check convergence: ||current - previous|| < 0.01 (C++ line 1173)
            if previous_landmarks is not None:
                shape_change = np.linalg.norm(current_landmarks - previous_landmarks)
                if shape_change < 0.01:
                    rigid_converged = True
                    break
            previous_landmarks = current_landmarks.copy()

            # Compute mean-shift using PRECOMPUTED response maps and current offsets
            mean_shift = self._compute_mean_shift(
                current_landmarks, base_landmarks_rigid, response_maps, patch_experts,
                window_size, sim_img_to_ref, sim_ref_to_img, iteration=rigid_iter
            )

            # Debug: Print mean-shift for first iteration
            if self.debug_mode and rigid_iter == 0:
                print(f"[PY][ITER0_WS{window_size}] RIGID Mean-shift vectors:")
                for lm_idx in self.tracked_landmarks:
                    if lm_idx < len(current_landmarks):
                        ms_x = mean_shift[2 * lm_idx]
                        ms_y = mean_shift[2 * lm_idx + 1]
                        ms_mag = np.sqrt(ms_x**2 + ms_y**2)
                        print(f"[PY][ITER0_WS{window_size}]   Landmark_{lm_idx}: ms=({ms_x:.4f}, {ms_y:.4f}) mag={ms_mag:.4f}")

            # Compute Jacobian for RIGID parameters only
            J_rigid = pdm.compute_jacobian_rigid(rigid_params)

            # Solve for rigid parameter update
            delta_p_rigid = self._solve_rigid_update(J_rigid, mean_shift, W, rigid_iter, window_size)

            # Update ONLY global parameters
            delta_p_full = np.zeros(len(rigid_params))
            delta_p_full[:6] = delta_p_rigid
            rigid_params = pdm.update_params(rigid_params, delta_p_full)
            rigid_params = pdm.clamp_params(rigid_params)

        # Copy rigid updates to params
        params[:6] = rigid_params[:6]

        # Debug: Print params after rigid phase
        if window_size == 11:
            print(f"\n[DEBUG] RIGID phase completed: {rigid_iter + 1} iterations, converged={rigid_converged}")
            print(f"[DEBUG]   Final rigid params: scale={params[0]:.6f}, rot=({params[1]:.6f}, {params[2]:.6f}, {params[3]:.6f})")
        if self.debug_mode:
            print(f"[PY][RIGID_COMPLETE] Rigid params after {rigid_iter + 1} iterations:")
            print(f"[PY][RIGID_COMPLETE]   scale: {params[0]:.6f}")
            print(f"[PY][RIGID_COMPLETE]   rotation: ({params[1]:.6f}, {params[2]:.6f}, {params[3]:.6f})")

        # =================================================================
        # PHASE 2: NON-RIGID optimization with inner convergence loop
        # Matches OpenFace LandmarkDetectorModel.cpp:868 NU_RLMS(..., rigid=false)
        # =================================================================

        # CRITICAL: base_landmarks for non-rigid uses RIGID-UPDATED params!
        # This makes first iteration offsets ≈ 0 (C++ lines 1197-1201)
        base_landmarks_nonrigid = pdm.params_to_landmarks_2d(params)
        previous_landmarks = None
        nonrigid_converged = False
        iteration_info = []

        # DEBUG: Print base_landmarks for non-rigid
        if window_size == 11:
            print(f"\n[DEBUG] NON-RIGID base landmarks (from rigid-updated params):")
            for lm_idx in [36, 48]:
                print(f"[DEBUG]   base_nonrigid[{lm_idx}]: ({base_landmarks_nonrigid[lm_idx][0]:.4f}, {base_landmarks_nonrigid[lm_idx][1]:.4f})")
            print(f"[DEBUG]   This should be DIFFERENT from initial landmarks!")
            print(f"[DEBUG]   Initial landmarks:")
            for lm_idx in [36, 48]:
                print(f"[DEBUG]   initial[{lm_idx}]: ({landmarks_2d_initial[lm_idx][0]:.4f}, {landmarks_2d_initial[lm_idx][1]:.4f})")

        for nonrigid_iter in range(self.max_iterations):
            # Compute current shape from params
            current_landmarks = pdm.params_to_landmarks_2d(params)

            # DEBUG: Print iteration info
            if window_size == 11 and nonrigid_iter < 2:
                print(f"\n[DEBUG] NON-RIGID iteration {nonrigid_iter}:")
                for lm_idx in [36, 48]:
                    offset_x = current_landmarks[lm_idx][0] - base_landmarks_nonrigid[lm_idx][0]
                    offset_y = current_landmarks[lm_idx][1] - base_landmarks_nonrigid[lm_idx][1]
                    print(f"[DEBUG]   Landmark {lm_idx}: current=({current_landmarks[lm_idx][0]:.4f}, {current_landmarks[lm_idx][1]:.4f})")
                    print(f"[DEBUG]   Landmark {lm_idx}: offset=({offset_x:.4f}, {offset_y:.4f})")

            # Check convergence: ||current - previous|| < 0.01
            if previous_landmarks is not None:
                shape_change = np.linalg.norm(current_landmarks - previous_landmarks)
                if shape_change < 0.01:
                    nonrigid_converged = True
                    if window_size == 11:
                        print(f"[DEBUG] NON-RIGID converged at iteration {nonrigid_iter}: shape_change={shape_change:.6f}")
                    break
            previous_landmarks = current_landmarks.copy()

            # Compute mean-shift using PRECOMPUTED response maps and current offsets
            # Offsets = current - base_nonrigid (where base = rigid-updated params)
            mean_shift = self._compute_mean_shift(
                current_landmarks, base_landmarks_nonrigid, response_maps, patch_experts,
                window_size, sim_img_to_ref, sim_ref_to_img, iteration=nonrigid_iter
            )

            # Debug: Print mean-shift for first iteration
            if self.debug_mode and nonrigid_iter == 0:
                print(f"[PY][ITER0_WS{window_size}] NONRIGID Mean-shift vectors:")
                for lm_idx in self.tracked_landmarks:
                    if lm_idx < len(current_landmarks):
                        ms_x = mean_shift[2 * lm_idx]
                        ms_y = mean_shift[2 * lm_idx + 1]
                        ms_mag = np.sqrt(ms_x**2 + ms_y**2)
                        print(f"[PY][ITER0_WS{window_size}]   Landmark_{lm_idx}: ms=({ms_x:.4f}, {ms_y:.4f}) mag={ms_mag:.4f}")

            # Compute full Jacobian (global + local)
            J = pdm.compute_jacobian(params)

            # Solve for full parameter update with regularization
            delta_p = self._solve_update(J, mean_shift, W, Lambda_inv, params, nonrigid_iter, window_size)

            # Update ALL parameters
            params = pdm.update_params(params, delta_p)
            params = pdm.clamp_params(params)

            # Track iteration info
            iteration_info.append({
                'iteration': nonrigid_iter,
                'update_magnitude': np.linalg.norm(delta_p),
                'params': params.copy()
            })

            # Debug: Print landmarks after iteration
            if self.debug_mode:
                iter_landmarks = pdm.params_to_landmarks_2d(params)
                print(f"[PY][ITER{nonrigid_iter + 1}_WS{window_size}] Landmark positions:")
                for lm_idx in self.tracked_landmarks:
                    if lm_idx < len(iter_landmarks):
                        print(f"[PY][ITER{nonrigid_iter + 1}_WS{window_size}]   Landmark_{lm_idx}: ({iter_landmarks[lm_idx][0]:.4f}, {iter_landmarks[lm_idx][1]:.4f})")

        # Determine overall convergence
        converged = rigid_converged and nonrigid_converged

        # Debug: Print non-rigid phase completion
        if window_size == 11:
            print(f"\n[DEBUG] NON-RIGID phase completed: {nonrigid_iter + 1} iterations, converged={nonrigid_converged}")
            print(f"[DEBUG]   Final params: scale={params[0]:.6f}, local[0]={params[6]:.6f}")

        # Return optimized parameters and info
        info = {
            'converged': converged,
            'iterations': len(iteration_info),
            'final_update': iteration_info[-1]['update_magnitude'] if iteration_info else 0.0,
            'iteration_history': iteration_info
        }

        return params, info

    def _compute_lambda_inv(self, pdm, n_params: int) -> np.ndarray:
        """
        Compute inverse regularization matrix Λ^(-1).

        For rigid parameters (scale, translation, rotation): no regularization (set to 0)
        For shape parameters: use inverse eigenvalues

        Args:
            pdm: PDM instance
            n_params: Total number of parameters

        Returns:
            Lambda_inv: Diagonal matrix (n_params,)
        """
        Lambda_inv = np.zeros(n_params)

        # No regularization for rigid parameters (indices 0-5)
        # These are: scale, tx, ty, wx, wy, wz
        Lambda_inv[:6] = 0.0

        # Shape parameters (indices 6+): use inverse eigenvalues
        eigenvalues = pdm.eigen_values.flatten()
        Lambda_inv[6:] = 1.0 / (eigenvalues + 1e-8)  # Add small epsilon for stability

        return Lambda_inv

    def _precompute_response_maps(self,
                                   landmarks_2d: np.ndarray,
                                   patch_experts: dict,
                                   image: np.ndarray,
                                   window_size: int,
                                   sim_img_to_ref: np.ndarray = None,
                                   sim_ref_to_img: np.ndarray = None,
                                   sigma_components: dict = None,
                                   iteration: int = None) -> dict:
        """
        Precompute response maps at initial landmark positions.

        This matches OpenFace's Response() call which computes response maps ONCE
        before optimization, then reuses them for both rigid and non-rigid phases.

        Args:
            landmarks_2d: Initial 2D landmark positions (n_points, 2)
            patch_experts: Dict mapping landmark_idx -> CCNFPatchExpert
            image: Grayscale image
            window_size: Response map size
            sim_img_to_ref: Similarity transform (image → reference)
            sim_ref_to_img: Similarity transform (reference → image)

        Returns:
            response_maps: Dict mapping landmark_idx -> response_map array
        """
        response_maps = {}
        use_warping = (sim_img_to_ref is not None and sim_ref_to_img is not None)

        for landmark_idx, patch_expert in patch_experts.items():
            lm_x, lm_y = landmarks_2d[landmark_idx]

            response_map = self._compute_response_map(
                image, lm_x, lm_y, patch_expert, window_size,
                sim_img_to_ref if use_warping else None,
                sim_ref_to_img if use_warping else None,
                sigma_components,
                landmark_idx, iteration
            )

            if response_map is not None:
                response_maps[landmark_idx] = response_map

        return response_maps

    def _compute_mean_shift(self,
                           landmarks_2d: np.ndarray,
                           base_landmarks_2d: np.ndarray,
                           response_maps: dict,
                           patch_experts: dict,
                           window_size: int = 11,
                           sim_img_to_ref: np.ndarray = None,
                           sim_ref_to_img: np.ndarray = None,
                           iteration: int = None) -> np.ndarray:
        """
        Compute mean-shift vector using PRECOMPUTED response maps and offsets.

        This matches OpenFace's NU_RLMS algorithm which:
        1. Uses response maps computed ONCE at initial positions
        2. Computes offsets: (current_landmarks - base_landmarks)
        3. Transforms offsets to reference coords (matching response map coords)
        4. Uses offsets to index into precomputed response maps
        5. Applies KDE mean-shift on the indexed responses

        Args:
            landmarks_2d: Current 2D landmark positions (n_points, 2)
            base_landmarks_2d: Base landmark positions where response maps were extracted
            response_maps: Dict of precomputed response maps (from _precompute_response_maps)
            patch_experts: Dict mapping landmark_idx -> CCNFPatchExpert
            window_size: Search window size
            sim_img_to_ref: Similarity transform (image → reference) for transforming offsets
            sim_ref_to_img: Similarity transform (reference → image) for transforming mean-shifts

        Returns:
            mean_shift: Mean-shift vector, shape (2 * n_points,)
        """
        n_points = landmarks_2d.shape[0]
        mean_shift = np.zeros(2 * n_points)

        # Gaussian kernel parameter for KDE: a_kde = -0.5 / sigma^2
        a_kde = -0.5 / (self.sigma * self.sigma)

        # Check if we should use warping (transforms provided)
        use_warping = (sim_img_to_ref is not None and sim_ref_to_img is not None)

        # Response map size
        resp_size = window_size

        # For each landmark with a precomputed response map
        for landmark_idx in response_maps.keys():
            if landmark_idx >= n_points:
                continue

            # Get precomputed response map (extracted at base landmark position)
            response_map = response_maps[landmark_idx]

            # Compute offset from base landmark to current landmark position IN IMAGE COORDS
            # This matches OpenFace C++ line 1197-1201:
            #   offsets = (current_shape - base_shape) * sim_img_to_ref
            curr_lm = landmarks_2d[landmark_idx]
            base_lm = base_landmarks_2d[landmark_idx]
            offset_img_x = curr_lm[0] - base_lm[0]
            offset_img_y = curr_lm[1] - base_lm[1]

            # DEBUG: Print offsets for landmark 36 on first iteration
            if landmark_idx == 36 and iteration == 0:
                print(f"[DEBUG] Landmark 36 offset (image coords): ({offset_img_x:.4f}, {offset_img_y:.4f})")
                print(f"[DEBUG]   curr_lm: ({curr_lm[0]:.4f}, {curr_lm[1]:.4f})")
                print(f"[DEBUG]   base_lm: ({base_lm[0]:.4f}, {base_lm[1]:.4f})")
                print(f"[DEBUG]   a_kde (Gaussian param): {a_kde:.6f}")

            # CRITICAL: Response maps are in REFERENCE coordinates (warped patches)
            # C++ transforms offsets: offsets = (current - base) * sim_img_to_ref
            if use_warping:
                # Transform offset vector from image to reference using 2x2 rotation/scale part
                # sim_img_to_ref format: [[a_sim, -b_sim, tx], [b_sim, a_sim, ty]]
                # For vector transformation we use: [a_sim -b_sim; b_sim a_sim] (the rotation/scale part)
                a_sim = sim_img_to_ref[0, 0]
                b_sim = sim_img_to_ref[1, 0]
                offset_ref_x = a_sim * offset_img_x + (-b_sim) * offset_img_y
                offset_ref_y = b_sim * offset_img_x + a_sim * offset_img_y

                # DEBUG: Print transformed offsets
                if landmark_idx == 36 and iteration == 0:
                    print(f"[DEBUG] Landmark 36 offset (ref coords): ({offset_ref_x:.4f}, {offset_ref_y:.4f})")
                    print(f"[DEBUG]   sim_img_to_ref[0,0] (a_sim): {a_sim:.6f}, sim_img_to_ref[1,0] (b_sim): {b_sim:.6f}")
            else:
                offset_ref_x = offset_img_x
                offset_ref_y = offset_img_y

            # Compute position within response map to evaluate
            # OpenFace C++ line 1203-1204:
            #   dxs = offsets.col(0) + (resp_size-1)/2
            #   dys = offsets.col(1) + (resp_size-1)/2
            center = (resp_size - 1) / 2.0

            # For RIGID: offset_ref = 0, so dx/dy = center
            # For NON-RIGID: offset_ref != 0, tracks how far rigid moved landmarks
            dx = offset_ref_x + center
            dy = offset_ref_y + center

            # Compute KDE mean-shift using OpenFace's algorithm
            # Result is in REFERENCE coordinates if warping was used
            # CRITICAL FIX: Pass a_kde (Gaussian param), not a_sim (similarity transform)!
            ms_ref_x, ms_ref_y = self._kde_mean_shift(
                response_map, dx, dy, a_kde, landmark_idx
            )

            if use_warping:
                # Transform mean-shift from REFERENCE back to IMAGE coordinates
                # Apply 2x2 rotation/scale matrix: [a_sim -b_sim; b_sim a_sim]
                a_mat = sim_ref_to_img[0, 0]
                b_mat = sim_ref_to_img[1, 0]
                ms_x = a_mat * ms_ref_x - b_mat * ms_ref_y
                ms_y = b_mat * ms_ref_x + a_mat * ms_ref_y
            else:
                ms_x = ms_ref_x
                ms_y = ms_ref_y

            mean_shift[2 * landmark_idx] = ms_x
            mean_shift[2 * landmark_idx + 1] = ms_y

            # DEBUG: Print mean-shift computation details for landmark 36
            if landmark_idx == 36 and iteration == 0 and window_size == 11:
                print(f"\n[DEBUG] Mean-shift computation for landmark 36:")
                print(f"[DEBUG]   dx={dx:.4f}, dy={dy:.4f} (position in response map)")
                print(f"[DEBUG]   ms_ref=({ms_ref_x:.4f}, {ms_ref_y:.4f}) (in reference coords)")
                print(f"[DEBUG]   ms_img=({ms_x:.4f}, {ms_y:.4f}) (in image coords)")
                print(f"[DEBUG]   Response map stats: min={response_map.min():.6f}, max={response_map.max():.6f}")

        # DEBUG: Print mean_shift vector stats
        if iteration == 0 and window_size == 11:
            print(f"\n[DEBUG] Mean-shift vector computed:")
            print(f"[DEBUG]   Total landmarks: {len(response_maps)}")
            print(f"[DEBUG]   Mean-shift norm: {np.linalg.norm(mean_shift):.4f}")
            print(f"[DEBUG]   Mean-shift for landmarks 36, 48:")
            for lm_idx in [36, 48]:
                if lm_idx in response_maps:
                    ms_x = mean_shift[2 * lm_idx]
                    ms_y = mean_shift[2 * lm_idx + 1]
                    print(f"[DEBUG]     Landmark {lm_idx}: ({ms_x:.4f}, {ms_y:.4f})")

        return mean_shift

    def _get_kde_kernel(self, window_size: int) -> np.ndarray:
        """
        Get or compute KDE kernel for given window size.

        Args:
            window_size: Size of response map window

        Returns:
            kde_kernel: Precomputed KDE kernel
        """
        if window_size in self.kde_cache:
            return self.kde_cache[window_size]

        # Compute KDE kernel (OpenFace uses step_size=0.1 for sub-pixel precision)
        step_size = 0.1
        a = -0.5 / (self.sigma * self.sigma)

        # Number of discrete positions
        n_steps = int(window_size / step_size)

        # Precompute kernel for all possible (dx, dy) positions
        kernel = np.zeros((n_steps, n_steps, window_size, window_size))

        for i_x in range(n_steps):
            dx = i_x * step_size
            for i_y in range(n_steps):
                dy = i_y * step_size

                # Compute Gaussian kernel centered at (dx, dy)
                for ii in range(window_size):
                    for jj in range(window_size):
                        dist_sq = (dy - ii)**2 + (dx - jj)**2
                        kernel[i_x, i_y, ii, jj] = np.exp(a * dist_sq)

        self.kde_cache[window_size] = kernel
        return kernel

    def _precompute_kde_grid(self, resp_size: int, a: float) -> np.ndarray:
        """
        Precompute KDE kernel grid for fast mean-shift calculation.

        Matches OpenFace C++ implementation (line 918-950) which uses
        0.1 pixel grid spacing for efficiency.

        Args:
            resp_size: Response map size
            a: Gaussian kernel parameter (-0.5 / sigma^2)

        Returns:
            kde_grid: Precomputed KDE weights, shape ((resp_size/0.1)^2, resp_size^2)
        """
        step_size = 0.1

        # Number of grid points in each dimension
        grid_size = int(resp_size / step_size + 0.5)

        # Precompute KDE weights for all grid positions
        # Each row corresponds to one (dx, dy) grid position
        # Each row has resp_size*resp_size values (one per response map pixel)
        kde_grid = np.zeros((grid_size * grid_size, resp_size * resp_size), dtype=np.float32)

        # Iterate over grid positions (matching C++ line 924-929)
        for x in range(grid_size):
            dx_grid = x * step_size
            for y in range(grid_size):
                dy_grid = y * step_size

                # Compute index for this grid position
                idx = x * grid_size + y

                # Compute KDE weights for all response map positions
                # C++ iterates ii then jj (lines 934-945)
                kde_idx = 0
                for ii in range(resp_size):
                    # vx = (dy - ii)^2 matching C++ line 936
                    vx = (dy_grid - ii) * (dy_grid - ii)
                    for jj in range(resp_size):
                        # vy = (dx - jj)^2 matching C++ line 939
                        vy = (dx_grid - jj) * (dx_grid - jj)

                        # KDE weight at this position (C++ line 942)
                        kde_grid[idx, kde_idx] = np.exp(a * (vx + vy))
                        kde_idx += 1

        return kde_grid

    def _kde_mean_shift(self,
                       response_map: np.ndarray,
                       dx: float,
                       dy: float,
                       a: float,
                       landmark_idx: int = -1) -> Tuple[float, float]:
        """
        Compute KDE-based mean-shift for a single landmark.

        Implements OpenFace's NonVectorisedMeanShift_precalc_kde algorithm
        with precomputed KDE grid for 0.1 pixel spacing.

        Args:
            response_map: Patch expert response map (window_size, window_size)
            dx: Current x offset within response map
            dy: Current y offset within response map
            a: Gaussian kernel parameter (-0.5 / sigma^2)
            landmark_idx: Landmark index for debugging

        Returns:
            (ms_x, ms_y): Mean-shift in x and y directions
        """
        resp_size = response_map.shape[0]
        step_size = 0.1

        # Get or create precomputed KDE grid for this response size
        cache_key = (resp_size, a)
        if cache_key not in self.kde_cache:
            self.kde_cache[cache_key] = self._precompute_kde_grid(resp_size, a)
        kde_grid = self.kde_cache[cache_key]

        # DEBUG: Print for landmark 36
        if landmark_idx == 36 and not hasattr(self, '_printed_lm36_meanshift'):
            print(f"\n[PY][MEANSHIFT] Landmark 36 mean-shift computation:")
            print(f"[PY][MEANSHIFT]   dx (before clamp): {dx}")
            print(f"[PY][MEANSHIFT]   dy (before clamp): {dy}")
            print(f"[PY][MEANSHIFT]   resp_size: {resp_size}")

        # Clamp dx, dy to valid range (C++ line 973-980)
        if dx < 0:
            dx = 0
        if dy < 0:
            dy = 0
        if dx > resp_size - step_size:
            dx = resp_size - step_size
        if dy > resp_size - step_size:
            dy = resp_size - step_size

        # Round to nearest grid point (C++ line 983-984)
        # C++ uses int cast which rounds down, +0.5 achieves rounding
        closest_col = int(dy / step_size + 0.5)
        closest_row = int(dx / step_size + 0.5)

        # Compute grid index (C++ line 986)
        grid_size = int(resp_size / step_size + 0.5)
        idx = closest_row * grid_size + closest_col

        # DEBUG: Print after clamp
        if landmark_idx == 36 and not hasattr(self, '_printed_lm36_meanshift'):
            print(f"[PY][MEANSHIFT]   dx (after clamp): {dx}")
            print(f"[PY][MEANSHIFT]   dy (after clamp): {dy}")
            print(f"[PY][MEANSHIFT]   closest_row: {closest_row}, closest_col: {closest_col}")
            print(f"[PY][MEANSHIFT]   kde_idx: {idx}")
            print(f"[PY][MEANSHIFT]   Response map stats:")
            print(f"[PY][MEANSHIFT]     shape: {response_map.shape}")
            print(f"[PY][MEANSHIFT]     min: {response_map.min()}")
            print(f"[PY][MEANSHIFT]     max: {response_map.max()}")
            print(f"[PY][MEANSHIFT]     mean: {response_map.mean()}")

        # Get precomputed KDE weights for this grid position
        kde_weights = kde_grid[idx]

        # Compute weighted mean-shift (C++ line 994-1013)
        mx = 0.0
        my = 0.0
        total_weight = 0.0

        # Iterate through response map and KDE weights
        # C++ uses iterators that advance sequentially through both
        kde_idx = 0

        # DEBUG: Print center values for landmark 36
        if landmark_idx == 36 and not hasattr(self, '_printed_lm36_meanshift'):
            center_ii, center_jj = 5, 5  # Center of 11x11 map
            print(f"[PY][MEANSHIFT]   Response at center (5,5): {response_map[center_ii, center_jj]:.8f}")
            print(f"[PY][MEANSHIFT]   Response at peak (5,4): {response_map[5, 4]:.8f}")
            # Save response map for detailed comparison
            import numpy as np
            np.save('/tmp/py_response_lm36.npy', response_map)

        for ii in range(resp_size):
            for jj in range(resp_size):
                # Get response value at this position
                resp_val = response_map[ii, jj]

                # Get KDE weight (stored sequentially as we iterate ii, jj)
                kde_weight = kde_weights[kde_idx]

                # Combined weight (C++ line 1004)
                weight = resp_val * kde_weight

                total_weight += weight
                mx += weight * jj
                my += weight * ii

                kde_idx += 1

        # Compute mean-shift (C++ line 1015-1016)
        if total_weight > 1e-10:
            ms_x = (mx / total_weight) - dx
            ms_y = (my / total_weight) - dy
        else:
            ms_x = 0.0
            ms_y = 0.0

        # DEBUG: Print final mean-shift for landmark 36
        if landmark_idx == 36 and not hasattr(self, '_printed_lm36_meanshift'):
            print(f"[PY][MEANSHIFT]   Accumulation results:")
            print(f"[PY][MEANSHIFT]     mx: {mx}")
            print(f"[PY][MEANSHIFT]     my: {my}")
            print(f"[PY][MEANSHIFT]     total_weight: {total_weight}")
            print(f"[PY][MEANSHIFT]   Final mean-shift:")
            print(f"[PY][MEANSHIFT]     ms_x: {ms_x}")
            print(f"[PY][MEANSHIFT]     ms_y: {ms_y}")
            self._printed_lm36_meanshift = True

        return ms_x, ms_y

    def _compute_response_map(self,
                             image: np.ndarray,
                             center_x: float,
                             center_y: float,
                             patch_expert,
                             window_size: int,
                             sim_img_to_ref: np.ndarray = None,
                             sim_ref_to_img: np.ndarray = None,
                             sigma_components: dict = None,
                             landmark_idx: int = None,
                             iteration: int = None) -> Optional[np.ndarray]:
        """
        Compute response map for a landmark in a window around current position.

        When sim_img_to_ref is provided, extracts a larger window around the landmark,
        warps it to reference coordinates using cv2.warpAffine, then evaluates patches
        from the warped window. This ensures patches see features at the scale they
        were trained on.

        Args:
            image: Input image
            center_x, center_y: Current landmark position in IMAGE coordinates
            patch_expert: CCNFPatchExpert for this landmark
            window_size: Size of search window
            sim_img_to_ref: Optional 2x3 similarity transform (IMAGE → REFERENCE)

        Returns:
            response_map: (window_size, window_size) array of patch responses
        """
        response_map = np.zeros((window_size, window_size))

        # Window bounds (centered at current landmark)
        half_window = window_size // 2

        if sim_img_to_ref is not None:
            # WARPING MODE: Mimic OpenFace's exact approach (line 240 in Patch_experts.cpp)
            # Calculate area of interest size
            # CEN uses width_support/height_support, CCNF uses width/height
            if hasattr(patch_expert, 'width_support'):
                patch_dim = max(patch_expert.width_support, patch_expert.height_support)
            else:
                patch_dim = max(patch_expert.width, patch_expert.height)
            area_of_interest_width = window_size + patch_dim - 1
            area_of_interest_height = window_size + patch_dim - 1

            # Extract rotation/scale components from sim_ref_to_img (the INVERSE transform)
            # OpenFace uses: a1 = sim_ref_to_img(0,0), b1 = -sim_ref_to_img(0,1)
            a1 = sim_ref_to_img[0, 0]
            b1 = -sim_ref_to_img[0, 1]  # Note the NEGATIVE sign!

            # Construct the transform exactly as OpenFace does (line 240)
            # This centers the landmark at (area_of_interest_width-1)/2 in the warped output
            center_offset = (area_of_interest_width - 1.0) / 2.0

            tx = center_x - a1 * center_offset + b1 * center_offset
            ty = center_y - a1 * center_offset - b1 * center_offset

            sim_matrix = np.array([
                [a1, -b1, tx],
                [b1,  a1, ty]
            ], dtype=np.float32)

            # Warp using WARP_INVERSE_MAP (OpenFace line 245)
            # This inverts sim_matrix, effectively applying sim_img_to_ref
            area_of_interest = cv2.warpAffine(
                image,
                sim_matrix,
                (area_of_interest_width, area_of_interest_height),
                flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR
            )

            # Now evaluate patches from the warped area_of_interest
            # The landmark is centered at (area_of_interest_width-1)/2
            center_warped = int((area_of_interest_width - 1) / 2)

            # DEBUG: Save area_of_interest for landmark 36
            if landmark_idx == 36 and iteration == 0:
                np.save('/tmp/area_of_interest_lm36.npy', area_of_interest)
                cv2.imwrite('/tmp/area_of_interest_lm36.png', area_of_interest)
                print(f"[PY][DEBUG] Saved area_of_interest for landmark 36:")
                print(f"[PY][DEBUG]   Shape: {area_of_interest.shape}")
                print(f"[PY][DEBUG]   Stats: min={area_of_interest.min()}, max={area_of_interest.max()}, mean={area_of_interest.mean():.1f}")
                print(f"[PY][DEBUG]   area_of_interest_width: {area_of_interest_width}")
                print(f"[PY][DEBUG]   patch_dim: {patch_dim}")
                print(f"[PY][DEBUG]   window_size: {window_size}")
                print(f"[PY][DEBUG]   sim_matrix:")
                print(f"[PY][DEBUG]     {sim_matrix}")

            # Check if this is CEN (has response() method) or CCNF (has compute_response())
            if hasattr(patch_expert, 'response') and not hasattr(patch_expert, 'compute_response'):
                # CEN: Call response() directly on area_of_interest - much faster!
                # This matches C++ CEN_patch_expert::Response() exactly

                # DEBUG: Check area_of_interest before calling response()
                if landmark_idx == 36 and iteration == 0:
                    print(f"[PY][DEBUG] area_of_interest BEFORE response():")
                    print(f"[PY][DEBUG]   dtype: {area_of_interest.dtype}, shape: {area_of_interest.shape}")
                    print(f"[PY][DEBUG]   min={area_of_interest.min()}, max={area_of_interest.max()}, mean={area_of_interest.mean():.1f}")
                    print(f"[PY][DEBUG]   sum={area_of_interest.sum()}")
                    print(f"[PY][DEBUG] patch_expert info:")
                    print(f"[PY][DEBUG]   type: {type(patch_expert)}")
                    print(f"[PY][DEBUG]   width: {patch_expert.width}, height: {patch_expert.height}")
                    if hasattr(patch_expert, 'width_support'):
                        print(f"[PY][DEBUG]   width_support: {patch_expert.width_support}, height_support: {patch_expert.height_support}")
                    # Save a second copy to compare
                    np.save('/tmp/area_of_interest_lm36_before_response.npy', area_of_interest.copy())

                response_map = patch_expert.response(area_of_interest)

                # DEBUG: Check response_map after calling response()
                if landmark_idx == 36 and iteration == 0:
                    print(f"[PY][DEBUG] response_map AFTER response():")
                    print(f"[PY][DEBUG]   dtype: {response_map.dtype}, shape: {response_map.shape}")
                    print(f"[PY][DEBUG]   min={response_map.min():.6f}, max={response_map.max():.6f}, mean={response_map.mean():.6f}")
                    print(f"[PY][DEBUG]   peak: {np.unravel_index(np.argmax(response_map), response_map.shape)} = {response_map.max():.6f}")
            else:
                # CCNF: Nested loop to evaluate each position
                start_x = center_warped - half_window
                start_y = center_warped - half_window

                for i in range(window_size):
                    for j in range(window_size):
                        patch_x = start_x + j
                        patch_y = start_y + i

                        # Extract patch from warped area_of_interest
                        patch = self._extract_patch(
                            area_of_interest, patch_x, patch_y,
                            patch_expert.width, patch_expert.height
                        )

                        if patch is not None:
                            response_map[i, j] = patch_expert.compute_response(patch)
                        else:
                            response_map[i, j] = -1e10
        else:
            # NO WARPING: Direct extraction from image (not typically used with OpenFace)
            # Check if this is CEN (has response() method) or CCNF (has compute_response())
            if hasattr(patch_expert, 'response') and not hasattr(patch_expert, 'compute_response'):
                # CEN: Extract area_of_interest and call response()
                # Calculate area size needed
                if hasattr(patch_expert, 'width_support'):
                    patch_dim = max(patch_expert.width_support, patch_expert.height_support)
                else:
                    patch_dim = max(patch_expert.width, patch_expert.height)

                area_width = window_size + patch_dim - 1
                area_height = window_size + patch_dim - 1
                half_area = area_width // 2

                # Extract area around landmark
                x1 = int(center_x - half_area)
                y1 = int(center_y - half_area)
                x2 = x1 + area_width
                y2 = y1 + area_height

                # Ensure bounds
                if x1 >= 0 and y1 >= 0 and x2 <= image.shape[1] and y2 <= image.shape[0]:
                    area_of_interest = image[y1:y2, x1:x2]
                    response_map = patch_expert.response(area_of_interest)
                else:
                    # Out of bounds - use low response
                    response_map[:] = -1e10
            else:
                # CCNF: Nested loop to evaluate each position
                start_x = int(center_x) - half_window
                start_y = int(center_y) - half_window

                # Compute response at each position in window
                for i in range(window_size):
                    for j in range(window_size):
                        patch_x = start_x + j
                        patch_y = start_y + i

                        # Extract patch at this position
                        patch = self._extract_patch(
                            image, patch_x, patch_y,
                            patch_expert.width, patch_expert.height
                        )

                        if patch is not None:
                            response_map[i, j] = patch_expert.compute_response(patch)
                        else:
                            response_map[i, j] = -1e10  # Very low response for out-of-bounds

        # DEBUG: Save response map BEFORE sigma for landmark 36
        if landmark_idx == 36 and iteration == 0 and window_size == 11:
            np.save('/tmp/python_response_map_lm36_iter0_ws11_BEFORE_SIGMA.npy', response_map)
            print(f"[PY][DEBUG] Saved BEFORE SIGMA response map for landmark 36 (WS={window_size}): shape={response_map.shape}, min={response_map.min():.6f}, max={response_map.max():.6f}, mean={response_map.mean():.6f}")

        # Apply CCNF Sigma transformation for spatial correlation modeling
        # (OpenFace CCNF_patch_expert.cpp lines 400-404)
        # Use response_map size (window_size × window_size), NOT patch size
        response_window_size = response_map.shape[0]  # Square response map

        # DEBUG: Track Sigma transformation
        sigma_applied = False
        peak_before = None
        peak_after = None

        if sigma_components is not None and response_window_size in sigma_components:
            try:
                # DEBUG: Peak location before Sigma
                peak_idx_before = np.unravel_index(response_map.argmax(), response_map.shape)
                center = response_window_size // 2
                offset_before = (peak_idx_before[1] - center, peak_idx_before[0] - center)
                peak_before = (peak_idx_before, offset_before, response_map.max())

                # Get sigma components for this response map window size
                sigma_comps = sigma_components[response_window_size]

                # DEBUG: Enable detailed Sigma computation logging for first landmark on first iteration
                debug_sigma = (landmark_idx == 36 and iteration == 0 and response_window_size == 11)

                if debug_sigma:
                    print(f"\n  [Sigma Component Selection Debug]")
                    print(f"    landmark_idx={landmark_idx}, iteration={iteration}")
                    print(f"    response_window_size={response_window_size}")
                    print(f"    Available sigma_components window sizes: {list(sigma_components.keys())}")
                    print(f"    Selected sigma_comps length: {len(sigma_comps)}")
                    for i, sc in enumerate(sigma_comps):
                        print(f"    sigma_comps[{i}].shape = {sc.shape}")

                # Compute Sigma covariance matrix with correct window size
                Sigma = patch_expert.compute_sigma(sigma_comps, window_size=response_window_size, debug=debug_sigma)

                # Apply transformation: response = Sigma @ response.reshape(-1, 1)
                # This models spatial correlations in the response map
                response_shape = response_map.shape
                response_vec = response_map.reshape(-1, 1)
                response_transformed = Sigma @ response_vec
                response_map = response_transformed.reshape(response_shape)

                # DEBUG: Peak location after Sigma
                peak_idx_after = np.unravel_index(response_map.argmax(), response_map.shape)
                offset_after = (peak_idx_after[1] - center, peak_idx_after[0] - center)
                peak_after = (peak_idx_after, offset_after, response_map.max())

                sigma_applied = True
            except Exception as e:
                # If Sigma transformation fails, continue with untransformed response
                print(f"Warning: Sigma transformation failed: {e}")

        # DEBUG: Print Sigma transformation results (only if significant offset)
        if peak_before is not None and peak_after is not None:
            offset_dist_before = np.sqrt(peak_before[1][0]**2 + peak_before[1][1]**2)
            offset_dist_after = np.sqrt(peak_after[1][0]**2 + peak_after[1][1]**2)
            if offset_dist_before > 3.0 or offset_dist_after > 3.0:
                # Check Sigma matrix properties
                response_range_before = response_map.max() - response_map.min()
                response_std = response_map.std()
                print(f"  SIGMA: ws={response_window_size} BEFORE: offset={peak_before[1]} dist={offset_dist_before:.1f}px peak={peak_before[2]:.3f}")
                print(f"  SIGMA: ws={response_window_size} AFTER:  offset={peak_after[1]} dist={offset_dist_after:.1f}px peak={peak_after[2]:.3f} range={response_range_before:.3f} std={response_std:.3f}")
        elif sigma_components is None:
            print(f"  WARNING: sigma_components is None! Sigma transformation skipped.")
        elif response_window_size not in sigma_components:
            print(f"  WARNING: window_size={response_window_size} not in sigma_components! Available: {list(sigma_components.keys())}")

        # OpenFace CCNF Response normalization (CCNF_patch_expert.cpp lines 406-413)
        # After computing responses, remove negative values by shifting
        # OpenFace C++ does ONLY this - no [0,1] normalization!
        min_val = response_map.min()
        if min_val < 0:
            response_map = response_map - min_val

        return response_map

    def _extract_patch(self,
                      image: np.ndarray,
                      center_x: int,
                      center_y: int,
                      patch_width: int,
                      patch_height: int) -> Optional[np.ndarray]:
        """
        Extract image patch centered at (center_x, center_y).

        Args:
            image: Source image
            center_x, center_y: Patch center coordinates
            patch_width, patch_height: Patch dimensions

        Returns:
            patch: Extracted patch, or None if out of bounds
        """
        half_w = patch_width // 2
        half_h = patch_height // 2

        # Compute patch bounds
        x1 = center_x - half_w
        y1 = center_y - half_h
        x2 = x1 + patch_width
        y2 = y1 + patch_height

        # Check bounds
        if x1 < 0 or y1 < 0 or x2 > image.shape[1] or y2 > image.shape[0]:
            return None

        # Extract patch
        patch = image[y1:y2, x1:x2]

        return patch

    def _solve_rigid_update(self,
                           J_rigid: np.ndarray,
                           v: np.ndarray,
                           W: np.ndarray,
                           iteration: int = -1,
                           window_size: int = -1) -> np.ndarray:
        """
        Solve for RIGID parameter update (scale, rotation, translation only).

        This is Phase 1 of two-phase optimization. Only updates global params
        while keeping local shape params at 0.

        Solves: Δp_global = (J_rigid^T·W·J_rigid)^(-1) · (J_rigid^T·W·v)

        Args:
            J_rigid: Jacobian for rigid params only (2n, 6)
            v: Mean-shift vector (2n,)
            W: Weight matrix (2n, 2n)
            iteration: Current iteration number (for debug)
            window_size: Current window size (for debug)

        Returns:
            delta_p_rigid: Parameter update for rigid params only (6,)
        """
        # Compute Hessian: A = J^T·W·J (no regularization for rigid params)
        A = J_rigid.T @ W @ J_rigid  # (6, 6)

        # Compute right-hand side: b = J^T·W·v
        b = J_rigid.T @ W @ v  # (6,)

        # DEBUG: Save parameter update details for first iteration RIGID phase
        if iteration == 0 and window_size == 11:
            import os
            with open('/tmp/python_param_update_iter0.txt', 'a' if os.path.exists('/tmp/python_param_update_iter0.txt') else 'w') as f:
                f.write(f"=== ITER0_WS11_RIGID ===\n")

                # Print intermediate computation details
                print(f"\n[DEBUG] RIGID J_w_t_m computation:")
                print(f"[DEBUG]   mean_shift norm: {np.linalg.norm(v):.4f}")
                print(f"[DEBUG]   W trace: {np.trace(W):.4f}, mean: {np.mean(np.diag(W)):.4f}")
                print(f"[DEBUG]   J_rigid shape: {J_rigid.shape}")
                print(f"[DEBUG]   J_rigid norm: {np.linalg.norm(J_rigid):.4f}")

                # Compute step by step
                W_v = W @ v
                print(f"[DEBUG]   W @ v norm: {np.linalg.norm(W_v):.4f}")
                print(f"[DEBUG]   b = J^T @ W @ v:")
                for i in range(len(b)):
                    print(f"[DEBUG]     b[{i}] = {b[i]:.4f}")

                # Save J_w_t_m (which is b in our case)
                f.write(f"J_w_t_m (size {len(b)}):\n")
                for i in range(len(b)):
                    f.write(f"  J_w_t_m[{i}]: {b[i]:.8f}\n")

                # Save Hessian diagonal
                f.write(f"Hessian diagonal:\n")
                for i in range(len(A)):
                    f.write(f"  Hessian[{i},{i}]: {A[i,i]:.8f}\n")

        # Solve linear system: A·Δp = b
        try:
            delta_p_rigid = np.linalg.solve(A, b)
        except np.linalg.LinAlgError:
            delta_p_rigid = np.linalg.lstsq(A, b, rcond=None)[0]

        # DEBUG: Save param_update after solving
        if iteration == 0 and window_size == 11:
            with open('/tmp/python_param_update_iter0.txt', 'a') as f:
                f.write(f"param_update (size {len(delta_p_rigid)}) BEFORE damping:\n")
                for i in range(len(delta_p_rigid)):
                    f.write(f"  param_update[{i}]: {delta_p_rigid[i]:.8f}\n")

        # Apply learning rate damping (OpenFace PDM.cpp line 660)
        delta_p_rigid = 0.75 * delta_p_rigid

        # DEBUG: Save param_update after damping
        if iteration == 0 and window_size == 11:
            with open('/tmp/python_param_update_iter0.txt', 'a') as f:
                f.write(f"param_update (size {len(delta_p_rigid)}) AFTER damping (0.75):\n")
                for i in range(len(delta_p_rigid)):
                    f.write(f"  param_update[{i}]: {delta_p_rigid[i]:.8f}\n")
                f.write(f"\n")

        return delta_p_rigid

    def _solve_update(self,
                     J: np.ndarray,
                     v: np.ndarray,
                     W: np.ndarray,
                     Lambda_inv: np.ndarray,
                     params: np.ndarray,
                     iteration: int = -1,
                     window_size: int = -1) -> np.ndarray:
        """
        Solve for parameter update using NU-RLMS equation.

        Solves: (J^T·W·J + λ·Λ^(-1))·Δp = J^T·W·v - λ·Λ^(-1)·p

        Args:
            J: Jacobian matrix (2n, m)
            v: Mean-shift vector (2n,)
            W: Weight matrix (2n, 2n)
            Lambda_inv: Inverse regularization matrix (m,)
            params: Current parameters (m,)
            iteration: Current iteration number (for debug)
            window_size: Current window size (for debug)

        Returns:
            delta_p: Parameter update (m,)
        """
        # Compute left-hand side: A = J^T·W·J + λ·Λ^(-1)
        JtWJ = J.T @ W @ J  # (m, m)
        Lambda_inv_diag = np.diag(self.regularization * Lambda_inv)  # (m, m)
        A = JtWJ + Lambda_inv_diag

        # Compute right-hand side: b = J^T·W·v - λ·Λ^(-1)·p
        JtWv = J.T @ W @ v  # (m,)
        reg_term = self.regularization * Lambda_inv * params  # (m,)
        b = JtWv - reg_term

        # DEBUG: Save parameter update details for first iteration NON-RIGID phase
        if iteration == 0 and window_size == 11:
            import os
            with open('/tmp/python_param_update_iter0.txt', 'a' if os.path.exists('/tmp/python_param_update_iter0.txt') else 'w') as f:
                f.write(f"=== ITER0_WS11_NONRIGID ===\n")

                # Save J_w_t_m (which is b in our case)
                f.write(f"J_w_t_m (size {len(b)}):\n")
                for i in range(min(20, len(b))):
                    f.write(f"  J_w_t_m[{i}]: {b[i]:.8f}\n")

                # Save Hessian diagonal (which is A in our case)
                f.write(f"Hessian diagonal (first 20):\n")
                for i in range(min(20, len(A))):
                    f.write(f"  Hessian[{i},{i}]: {A[i,i]:.8f}\n")

                # Will save param_update after solving
                f.write(f"(param_update will be computed next)\n")

                # Save current params before update
                f.write(f"current_params BEFORE update:\n")
                f.write(f"  scale: {params[0]:.8f}\n")
                f.write(f"  rot_x: {params[1]:.8f}\n")
                f.write(f"  rot_y: {params[2]:.8f}\n")
                f.write(f"  rot_z: {params[3]:.8f}\n")
                f.write(f"  trans_x: {params[4]:.8f}\n")
                f.write(f"  trans_y: {params[5]:.8f}\n")

                f.write(f"current_local BEFORE update (first 10):\n")
                for i in range(min(10, len(params) - 6)):
                    f.write(f"  current_local[{i}]: {params[6+i]:.8f}\n")

        # Solve linear system: A·Δp = b
        try:
            delta_p = np.linalg.solve(A, b)
        except np.linalg.LinAlgError:
            # If singular, use pseudo-inverse
            delta_p = np.linalg.lstsq(A, b, rcond=None)[0]

        # DEBUG: Save param_update after solving
        if iteration == 0 and window_size == 11:
            with open('/tmp/python_param_update_iter0.txt', 'a') as f:
                f.write(f"param_update (size {len(delta_p)}) BEFORE damping:\n")
                for i in range(min(20, len(delta_p))):
                    f.write(f"  param_update[{i}]: {delta_p[i]:.8f}\n")

        # Apply learning rate damping (OpenFace PDM.cpp line 660)
        # OpenFace uses 0.75 learning rate to dampen parameter updates
        delta_p = 0.75 * delta_p

        # DEBUG: Save param_update after damping
        if iteration == 0 and window_size == 11:
            with open('/tmp/python_param_update_iter0.txt', 'a') as f:
                f.write(f"param_update (size {len(delta_p)}) AFTER damping (0.75):\n")
                for i in range(min(20, len(delta_p))):
                    f.write(f"  param_update[{i}]: {delta_p[i]:.8f}\n")
                f.write(f"\n")

        return delta_p


def test_optimizer():
    """Test NU-RLMS optimizer."""
    print("=" * 60)
    print("Testing NU-RLMS Optimizer")
    print("=" * 60)

    # Import dependencies
    from pyclnf.core.pdm import PDM
    from pyclnf.core.patch_expert import CCNFPatchExpert

    # Test 1: Load PDM
    print("\nTest 1: Initialize optimizer and PDM")
    pdm = PDM("pyclnf/models/exported_pdm")
    optimizer = NURLMSOptimizer(
        regularization=1.0,
        max_iterations=5,
        convergence_threshold=0.1
    )
    print(f"  PDM loaded: {pdm.n_points} landmarks, {pdm.n_params} params")
    print(f"  Optimizer: max_iter={optimizer.max_iterations}, λ={optimizer.regularization}")

    # Test 2: Initialize parameters
    print("\nTest 2: Initialize parameters from bbox")
    bbox = (100, 100, 200, 250)
    initial_params = pdm.init_params(bbox)
    print(f"  Initial params shape: {initial_params.shape}")
    print(f"  Scale: {initial_params[0]:.3f}")
    print(f"  Translation: ({initial_params[1]:.1f}, {initial_params[2]:.1f})")

    # Test 3: Create synthetic test image
    print("\nTest 3: Create test scenario")
    test_image = np.random.randint(0, 256, (400, 400), dtype=np.uint8)

    # Load a few patch experts for testing
    from pathlib import Path
    patch_experts = {}
    for landmark_idx in [30, 36, 45]:  # Nose tip, eye corners
        patch_dir = Path(f"pyclnf/models/exported_ccnf_0.25/view_00/patch_{landmark_idx:02d}")
        if patch_dir.exists():
            try:
                patch_experts[landmark_idx] = CCNFPatchExpert(str(patch_dir))
            except:
                pass

    print(f"  Test image: {test_image.shape}")
    print(f"  Loaded {len(patch_experts)} patch experts")

    # Test 4: Test mean-shift computation
    print("\nTest 4: Compute mean-shift vector")
    landmarks_2d = pdm.params_to_landmarks_2d(initial_params)
    mean_shift = optimizer._compute_mean_shift(
        landmarks_2d, patch_experts, test_image, pdm
    )
    print(f"  Mean-shift shape: {mean_shift.shape}")
    print(f"  Mean-shift magnitude: {np.linalg.norm(mean_shift):.3f}")
    print(f"  Non-zero elements: {np.count_nonzero(mean_shift)}")

    # Test 5: Test update computation
    print("\nTest 5: Compute parameter update")
    J = pdm.compute_jacobian(initial_params)
    W = np.eye(2 * pdm.n_points)
    Lambda_inv = optimizer._compute_lambda_inv(pdm, pdm.n_params)

    delta_p = optimizer._solve_update(J, mean_shift, W, Lambda_inv, initial_params)
    print(f"  Delta params shape: {delta_p.shape}")
    print(f"  Update magnitude: {np.linalg.norm(delta_p):.6f}")
    print(f"  Max update component: {np.abs(delta_p).max():.6f}")

    # Test 6: Run full optimization
    print("\nTest 6: Run optimization loop")
    optimized_params, info = optimizer.optimize(
        pdm, initial_params, patch_experts, test_image
    )

    print(f"  Converged: {info['converged']}")
    print(f"  Iterations: {info['iterations']}")
    print(f"  Final update: {info['final_update']:.6f}")
    print(f"  Parameter change: {np.linalg.norm(optimized_params - initial_params):.6f}")

    # Test 7: Verify optimized landmarks
    print("\nTest 7: Compare initial vs optimized landmarks")
    initial_landmarks = pdm.params_to_landmarks_2d(initial_params)
    optimized_landmarks = pdm.params_to_landmarks_2d(optimized_params)

    landmark_shift = np.linalg.norm(optimized_landmarks - initial_landmarks, axis=1)
    print(f"  Mean landmark shift: {landmark_shift.mean():.3f} pixels")
    print(f"  Max landmark shift: {landmark_shift.max():.3f} pixels")
    print(f"  Landmarks moved > 1px: {np.sum(landmark_shift > 1.0)}")

    print("\n" + "=" * 60)
    print("✓ NU-RLMS Optimizer Tests Complete!")
    print("=" * 60)


if __name__ == "__main__":
    test_optimizer()
